{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lenskit import batch, topn, util\n",
    "from lenskit import crossfold as xf\n",
    "from lenskit.algorithms import Recommender, als, item_knn as knn\n",
    "from lenskit import topn\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('dataSets/jester_dataset_2/jester_ratings.dat', sep='\\t\\t' , names=['user', 'item', 'rating'])\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          user  item  rating\n",
      "0            1     5  10.219\n",
      "1            1     7   0.719\n",
      "2            1     8   0.719\n",
      "3            1    13   3.219\n",
      "4            1    15  10.875\n",
      "5            1    16   0.344\n",
      "6            1    17   0.969\n",
      "7            1    18   2.531\n",
      "8            1    19   1.281\n",
      "9            1    20   0.844\n",
      "10           1    21   2.812\n",
      "11           1    22   1.219\n",
      "12           1    23   1.469\n",
      "13           1    24   2.094\n",
      "14           1    25   2.531\n",
      "15           1    89  19.812\n",
      "16           1    50  19.906\n",
      "17           1   102  10.750\n",
      "18           1   103   5.000\n",
      "19           1   104  12.938\n",
      "20           1   105  12.000\n",
      "21           1   106   9.844\n",
      "22           1   107  12.031\n",
      "23           1   108  15.688\n",
      "24           1   109  19.656\n",
      "25           1    87  18.000\n",
      "26           1    93  19.312\n",
      "27           1    76  19.312\n",
      "28           1    65  18.781\n",
      "29           1    72  18.781\n",
      "...        ...   ...     ...\n",
      "1761409  63978    81  17.531\n",
      "1761410  63978   142  17.844\n",
      "1761411  63978    83  19.438\n",
      "1761412  63978    21   4.562\n",
      "1761413  63978    26  18.906\n",
      "1761414  63978    91  18.562\n",
      "1761415  63978    23  18.844\n",
      "1761416  63978   131  18.938\n",
      "1761417  63978    86   5.031\n",
      "1761418  63978    94   3.438\n",
      "1761419  63978    55   2.250\n",
      "1761420  63978    67   3.188\n",
      "1761421  63978    38   4.844\n",
      "1761422  63978   140   3.500\n",
      "1761423  63978    37   2.938\n",
      "1761424  63978    45   3.406\n",
      "1761425  63978   141   1.688\n",
      "1761426  63978    60   2.719\n",
      "1761427  63978   123   3.250\n",
      "1761428  63978    40  18.375\n",
      "1761429  63978    85   2.281\n",
      "1761430  63978    33   2.531\n",
      "1761431  63978   101   2.938\n",
      "1761432  63978    74   1.719\n",
      "1761433  63978    64   1.812\n",
      "1761434  63978    57   1.469\n",
      "1761435  63978    24   0.938\n",
      "1761436  63978   124   0.969\n",
      "1761437  63978    58   1.344\n",
      "1761438  63978    44   1.562\n",
      "\n",
      "[1761439 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "ratings.rating += 10\n",
    "print(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_ii = knn.ItemItem(20)\n",
    "algo_als = als.BiasedMF(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(aname, algo, train, test):\n",
    "    fittable = util.clone(algo)\n",
    "    fittable = Recommender.adapt(fittable)\n",
    "    fittable.fit(train)\n",
    "    users = test.user.unique()\n",
    "    # now we run the recommender\n",
    "    recs = batch.recommend(fittable, users, 10)\n",
    "    # add the algorithm name for analyzability\n",
    "    recs['Algorithm'] = aname\n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_recs = []\n",
    "test_data = []\n",
    "for train, test in xf.partition_users(ratings[['user', 'item', 'rating']], 5, xf.SampleFrac(0.2)):\n",
    "    test_data.append(test)\n",
    "    all_recs.append(eval('ItemItem', algo_ii, train, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_recs = pd.concat(all_recs, ignore_index=True)\n",
    "print(all_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.concat(test_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rla = topn.RecListAnalysis()\n",
    "rla.add_metric(topn.ndcg)\n",
    "results = rla.compute(all_recs, test_data)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.groupby('Algorithm').ndcg.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
